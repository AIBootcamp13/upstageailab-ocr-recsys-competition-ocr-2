# Critical Performance Bug Investigation
**Date**: 2025-10-10
**Status**: üî¥ **INVESTIGATING**

---

## Problem Statement

Model produces extremely poor results even though all tests pass:
- **Validation H-mean**: 0.00075 (should be ~0.4-0.6 for trained model)
- **Test H-mean**: 0.003
- **Test Precision**: 0.084
- **Test Recall**: 0.002

**Visual Evidence**: Predictions appear "stuck together" in clusters, no correlation with ground truth.

---

## Initial Hypotheses

### 1. Type Checking Issue (User's Hypothesis)
**Theory**: NumPy vs PIL array confusion causing silent data corruption

**Check Points**:
- Data flow: transforms ‚Üí base.py ‚Üí db_collate.py
- Type conversions that might corrupt data
- Array dtype changes (uint8 ‚Üí float32 ‚Üí uint8)

### 2. Transform Pipeline Issue
**Theory**: Augmentations corrupting data or labels

**Check Points**:
- Are keypoints being transformed correctly?
- Are inverse matrices computed correctly?
- Are polygons in correct coordinate frame?

### 3. Collate Function Issue
**Theory**: Target map generation broken

**Check Points**:
- Are probability maps being generated correctly?
- Are threshold maps correct?
- Are polygons being processed correctly?

### 4. Configuration Issue
**Theory**: Wrong config being used

**Check Points**:
- Using `data=default` as specified
- No preprocessing enabled for training
- Correct model architecture

---

## Investigation Plan

### Phase 1: Verify Data Loading (CURRENT)
1. ‚úÖ Check if images load correctly
2. ‚è≥ Check if polygons load correctly
3. ‚è≥ Verify image-polygon correspondence
4. ‚è≥ Check data types at each stage

### Phase 2: Verify Transforms
1. ‚è≥ Check if transforms preserve image quality
2. ‚è≥ Check if keypoint transforms are correct
3. ‚è≥ Verify inverse matrix computation
4. ‚è≥ Check polygon coordinate frames

### Phase 3: Verify Collate Function
1. ‚è≥ Check probability map generation
2. ‚è≥ Check threshold map generation
3. ‚è≥ Verify map shapes and values

### Phase 4: Run Diagnostic Training
1. ‚è≥ Training with small data (already done in our earlier test!)
2. ‚è≥ Compare results

---

## Key Observation

**WAIT!** In our earlier integration test, we got:
```
val/hmean: 0.000
test/hmean: 0.000
```

But we only trained for **1 epoch with 50 batches** on limited data.

The user's bug report shows:
```
trainer.max_epochs=3
```

**Question**: Did they actually train for 3 full epochs? Or did training stop early?

---

## Next Steps

1. ‚è≥ Check WandB run to see actual training details
2. ‚è≥ Run the exact command from bug report
3. ‚è≥ Compare with our working baseline test
4. ‚è≥ Add data validation checks

---

**Status**: Awaiting more information about training run
