# @package _global_

# Global batch size setting for dataloaders
batch_size: 12

# Data configuration
data:
  # Dataset size limits for faster iterations
  train_num_samples: 500  # Limit training to 500 samples
  val_num_samples: 50     # Limit validation to 50 samples
  test_num_samples: 50    # Limit test to 50 samples

  # Polygon cache configuration (optional for speedup)
  polygon_cache:
    enabled: false  # Set to true to enable 5-8x validation speedup
    max_size: 1000  # Maximum number of cached entries
    persist_to_disk: true
    cache_dir: .cache/polygon_cache

dataset_base_path: "${hydra:runtime.cwd}/data/datasets/"

datasets:
  train_dataset:
    _target_: ${dataset_path}.OCRDataset
    image_path: ${dataset_base_path}images/train
    annotation_path: ${dataset_base_path}jsons/train.json
    transform: ${transforms.train_transform}
  val_dataset:
    _target_: ${dataset_path}.OCRDataset
    image_path: ${dataset_base_path}images/val
    annotation_path: ${dataset_base_path}jsons/val.json
    transform: ${transforms.val_transform}
  test_dataset:
    _target_: ${dataset_path}.OCRDataset
    image_path: ${dataset_base_path}images_val_canonical  # Using canonical (rotation-corrected) data
    annotation_path: ${dataset_base_path}jsons/val.json
    transform: ${transforms.test_transform}
  predict_dataset:
    _target_: ${dataset_path}.OCRDataset
    image_path: ${dataset_base_path}images/test
    annotation_path: null
    transform: ${transforms.test_transform}

collate_fn:
  _target_: ${dataset_path}.DBCollateFN
  shrink_ratio: 0.4
  thresh_min: 0.3
  thresh_max: 0.7
  cache: null  # Set to PolygonCache instance to enable caching
